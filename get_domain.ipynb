{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fcf3ec1",
   "metadata": {},
   "source": [
    "# Get Domain\n",
    "\n",
    "**Author:** Andrew Loeppky (Lots of code stolen from Jamie Byer)\n",
    "\n",
    "**Project:** Land-surface-atmosphere coupling - CMIP6 intercomparison \n",
    "\n",
    "This code grabs a climate model from the cloud, screens it for required variable fields, then selects a user specified domain and saves it to disk as a netcdf4 file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57879880",
   "metadata": {},
   "source": [
    "## Part I: Get a CMIP 6 Dataset and Select Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42eb2a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pooch\n",
    "import pandas as pd\n",
    "import fsspec\n",
    "from pathlib import Path\n",
    "import time\n",
    "import numpy as np\n",
    "import json\n",
    "import cftime\n",
    "import matplotlib.pyplot as plt\n",
    "import netCDF4 as nc\n",
    "\n",
    "\n",
    "# Handy metpy tutorial working with xarray:\n",
    "# https://unidata.github.io/MetPy/latest/tutorials/xarray_tutorial.html#sphx-glr-tutorials-xarray-tutorial-py\n",
    "import metpy.calc as mpcalc\n",
    "from metpy.cbook import get_test_data\n",
    "from metpy.units import units\n",
    "from metpy.plots import SkewT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58229f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching domain:\n",
      "          source_id = 'GFDL-ESM4'\n",
      "          experiment_id = 'piControl'\n",
      "          table_id = '3hr'\n",
      "          lats = (15, 20)\n",
      "          lons = (25, 29)\n",
      "          years = (100, 105)\n",
      "          dataset name: my_ds (xarray Dataset)\n"
     ]
    }
   ],
   "source": [
    "# Attributes of the model we want to analyze (put in csv later)\n",
    "#source_id = 'CESM2-SE'\n",
    "source_id = 'GFDL-ESM4'\n",
    "experiment_id = 'piControl'\n",
    "#table_id = 'Amon'\n",
    "table_id = '3hr'\n",
    "\n",
    "# Domain we wish to study\n",
    "lats = (15, 20) # lat min, lat max\n",
    "lons = (25, 29) # lon min, lon max\n",
    "years = (100, 105) # start year, end year (note, no leap days)\n",
    "#ceil = 500 # top of domain, hPa\n",
    "\n",
    "\n",
    "print(f\"\"\"Fetching domain:\n",
    "          {source_id = }\n",
    "          {experiment_id = }\n",
    "          {table_id = }\n",
    "          {lats = }\n",
    "          {lons = }\n",
    "          {years = }\n",
    "          dataset name: my_ds (xarray Dataset)\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc66ecd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of fields required for input calculations\n",
    "required_fields = (\"ps\",  # surface pressure\n",
    "                      \"cl\",  # cloud fraction\n",
    "                      \"ta\",  # air temperature\n",
    "                      \"ts\",  # surface temperature\n",
    "                      \"hus\", # specific humidity\n",
    "                      \"hfls\", # Surface Upward Latent Heat Flux\n",
    "                      \"hfss\", # Surface Upward Sensible Heat Flux\n",
    "                      \"rlds\",  # surface downwelling longwave\n",
    "                      \"rlus\",  # surface upwelling longwave\n",
    "                      \"rsds\", # downwelling short wave\n",
    "                      \"rsus\", # upwelling short wave\n",
    "                      \"hurs\",  # near surface RH\n",
    "                      \"pr\", # precipitation, all phases\n",
    "                      \"evspsbl\", # evaporation, sublimation, transpiration\n",
    "                      \"wap\",  # omega (subsidence rate in pressure coords)\n",
    "                   )\n",
    "\n",
    "required_fields = ['tas', 'mrsos', 'mrro', 'tslsi', 'huss'] # temporary hack, but this will work for fig 11\n",
    "# i need to know which models we intend to parse for this project, they do not all have the same fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83efcfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get esm datastore\n",
    "odie = pooch.create(\n",
    "    path=\"./.cache\",\n",
    "    base_url=\"https://storage.googleapis.com/cmip6/\",\n",
    "    registry={\n",
    "        \"pangeo-cmip6.csv\": None\n",
    "    },\n",
    ")\n",
    "file_path = odie.fetch(\"pangeo-cmip6.csv\")\n",
    "df_in = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01d1ec8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7077/3986708080.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  available_fields = list(df_in[df_in.source_id == source_id][df_in.experiment_id == experiment_id][df_in.table_id == table_id].variable_id)\n"
     ]
    }
   ],
   "source": [
    "# extract the names of all fields in our selected model run\n",
    "available_fields = list(df_in[df_in.source_id == source_id][df_in.experiment_id == experiment_id][df_in.table_id == table_id].variable_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d5dee47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tas', 'mrsos', 'mrro', 'tslsi', 'huss']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "available_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "173ec2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that our run has all required fields, list problem variables\n",
    "fields_of_interest = []\n",
    "missing_fields = []\n",
    "for rq in required_fields:\n",
    "    if rq not in available_fields:\n",
    "        missing_fields.append(rq)\n",
    "    else:\n",
    "        fields_of_interest.append(rq)\n",
    "\n",
    "if missing_fields != []:\n",
    "    print(f\"\"\"WARNING: data from model run:\n",
    "\n",
    "                {source_id}, \n",
    "                {table_id}, \n",
    "                {experiment_id} \n",
    "\n",
    "         missing required field(s): {missing_fields}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "916353e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_var_exact(the_dict,df_og):\n",
    "    the_keys = list(the_dict.keys())\n",
    "    #print(the_keys)\n",
    "    key0 = the_keys[0]\n",
    "    #print(key0)\n",
    "    #print(the_dict[key0])\n",
    "    hit0 = df_og[key0] == the_dict[key0]\n",
    "    if len(the_keys) > 1:\n",
    "        hitnew = hit0\n",
    "        for key in the_keys[1:]:\n",
    "            hit = df_og[key] == the_dict[key]\n",
    "            hitnew = np.logical_and(hitnew,hit)\n",
    "            #print(\"total hits: \",np.sum(hitnew))\n",
    "    else:\n",
    "        hitnew = hit0\n",
    "    df_result = df_og[hitnew]\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "782a561d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_field(variable_id, \n",
    "              df,\n",
    "              source_id=source_id,\n",
    "              experiment_id=experiment_id,\n",
    "              table_id=table_id):\n",
    "    \"\"\"\n",
    "    extracts a single variable field from the model\n",
    "    \"\"\"\n",
    "\n",
    "    var_dict = dict(source_id = source_id, variable_id = variable_id,\n",
    "                    experiment_id = experiment_id, table_id = table_id)\n",
    "    \n",
    "    local_var = fetch_var_exact(var_dict, df)\n",
    "    zstore_url = local_var['zstore'].array[0]\n",
    "    the_mapper=fsspec.get_mapper(zstore_url)\n",
    "    local_var = xr.open_zarr(the_mapper, consolidated=True)\n",
    "    return local_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85bae45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_field(df, lat, lon, years):\n",
    "    \"\"\"\n",
    "    cuts out a specified domain from an xarrray field\n",
    "    \n",
    "    lat = (minlat, maxlat)\n",
    "    lon = (minlon, maxlon)\n",
    "    \"\"\"\n",
    "    new_field = df.sel(lat=slice(lat[0],lat[1]), lon=slice(lon[0],lon[1]))\n",
    "    new_field = new_field.isel(time=(new_field.time.dt.year > years[0]))\n",
    "    new_field = new_field.isel(time=(new_field.time.dt.year < years[1]))\n",
    "    return new_field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b734326d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully acquired domain\n"
     ]
    }
   ],
   "source": [
    "# grab all fields of interest and combine\n",
    "my_fields = [get_field(field, df_in) for field in fields_of_interest]\n",
    "small_fields = [trim_field(field, lats, lons, years) for field in my_fields]\n",
    "my_ds = xr.combine_by_coords(small_fields, compat=\"broadcast_equals\", combine_attrs=\"drop_conflicts\")\n",
    "print(\"Successfully acquired domain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a3afa1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from cftime import date2num\n",
    "#date2num(my_ds.time, \"minutes since 0000-01-01 00:00:00\", calendar=\"noleap\", has_year_zero=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85470fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as netcdf as per these recommendations:\n",
    "# https://xarray.pydata.org/en/stable/user-guide/dask.html#chunking-and-performance\n",
    "# netcdf cant handle cftime, so convert to ordinal, then back once the file is reopened\n",
    "my_ds[\"time\"] = date2num(my_ds.time, \"minutes since 0000-01-01 00:00:00\", calendar=\"noleap\", has_year_zero=True)\n",
    "my_ds = my_ds.drop(\"time_bnds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6a4dd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_ds.to_netcdf(f\"./data/{source_id}-{experiment_id}.nc\", engine=\"netcdf4\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
