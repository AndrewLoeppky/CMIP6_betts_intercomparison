{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fcf3ec1",
   "metadata": {},
   "source": [
    "# Scratch Book\n",
    "\n",
    "**Author:** Andrew Loeppky (Lots of code stolen from Jamie Byer)\n",
    "\n",
    "**Project:** Land-surface-atmosphere coupling - CMIP6 intercomparison \n",
    "\n",
    "experiment space for writing, testing code related to Betts CMIP6 intercomparison project\n",
    "\n",
    "**Workflow:** \n",
    "\n",
    "1) get raw xarrays using Jamie's model fetching code. Screen models which do not contain required fields for doing the calculations\n",
    "\n",
    "2) convert to metpy CF standards using `metpy.parse_cf(<raw_xarray>)`. Generate the necessary fields to make the figures we want. \n",
    "\n",
    "3) pare fields down to the most naive data type allowable (numpy arrays?) and plot with matplotlib (not some weird wrapper for matplotlib, too buggy)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57879880",
   "metadata": {},
   "source": [
    "## Part I: Get a CMIP 6 Dataset and Select Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42eb2a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pooch\n",
    "import pandas as pd\n",
    "import fsspec\n",
    "from pathlib import Path\n",
    "import time\n",
    "import numpy as np\n",
    "import json\n",
    "import cftime\n",
    "import matplotlib.pyplot as plt\n",
    "import netCDF4 as nc\n",
    "\n",
    "\n",
    "# Handy metpy tutorial working with xarray:\n",
    "# https://unidata.github.io/MetPy/latest/tutorials/xarray_tutorial.html#sphx-glr-tutorials-xarray-tutorial-py\n",
    "import metpy.calc as mpcalc\n",
    "from metpy.cbook import get_test_data\n",
    "from metpy.units import units\n",
    "from metpy.plots import SkewT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58229f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching domain:\n",
      "          source_id = 'GFDL-ESM4'\n",
      "          experiment_id = 'piControl'\n",
      "          table_id = '3hr'\n",
      "          lats = (15, 20)\n",
      "          lons = (25, 29)\n",
      "          years = (100, 105)\n",
      "          dataset name: my_ds (xarray Dataset)\n"
     ]
    }
   ],
   "source": [
    "# Attributes of the model we want to analyze (put in csv later)\n",
    "#source_id = 'CESM2-SE'\n",
    "source_id = 'GFDL-ESM4'\n",
    "experiment_id = 'piControl'\n",
    "#table_id = 'Amon'\n",
    "table_id = '3hr'\n",
    "\n",
    "# Domain we wish to study\n",
    "lats = (15, 20) # lat min, lat max\n",
    "lons = (25, 29) # lon min, lon max\n",
    "years = (100, 105) # start year, end year (note, no leap days)\n",
    "#ceil = 500 # top of domain, hPa\n",
    "\n",
    "\n",
    "print(f\"\"\"Fetching domain:\n",
    "          {source_id = }\n",
    "          {experiment_id = }\n",
    "          {table_id = }\n",
    "          {lats = }\n",
    "          {lons = }\n",
    "          {years = }\n",
    "          dataset name: my_ds (xarray Dataset)\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc66ecd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of fields required for input calculations\n",
    "required_fields = (\"ps\",  # surface pressure\n",
    "                      \"cl\",  # cloud fraction\n",
    "                      \"ta\",  # air temperature\n",
    "                      \"ts\",  # surface temperature\n",
    "                      \"hus\", # specific humidity\n",
    "                      \"hfls\", # Surface Upward Latent Heat Flux\n",
    "                      \"hfss\", # Surface Upward Sensible Heat Flux\n",
    "                      \"rlds\",  # surface downwelling longwave\n",
    "                      \"rlus\",  # surface upwelling longwave\n",
    "                      \"rsds\", # downwelling short wave\n",
    "                      \"rsus\", # upwelling short wave\n",
    "                      \"hurs\",  # near surface RH\n",
    "                      \"pr\", # precipitation, all phases\n",
    "                      \"evspsbl\", # evaporation, sublimation, transpiration\n",
    "                      \"wap\",  # omega (subsidence rate in pressure coords)\n",
    "                   )\n",
    "\n",
    "required_fields = ['tas', 'mrsos', 'mrro', 'tslsi', 'huss'] # temporary hack, but this will work for fig 11\n",
    "# i need to know which models we intend to parse for this project, they do not all have the same fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83efcfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get esm datastore\n",
    "odie = pooch.create(\n",
    "    path=\"./.cache\",\n",
    "    base_url=\"https://storage.googleapis.com/cmip6/\",\n",
    "    registry={\n",
    "        \"pangeo-cmip6.csv\": None\n",
    "    },\n",
    ")\n",
    "file_path = odie.fetch(\"pangeo-cmip6.csv\")\n",
    "df_in = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01d1ec8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6349/3986708080.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  available_fields = list(df_in[df_in.source_id == source_id][df_in.experiment_id == experiment_id][df_in.table_id == table_id].variable_id)\n"
     ]
    }
   ],
   "source": [
    "# extract the names of all fields in our selected model run\n",
    "available_fields = list(df_in[df_in.source_id == source_id][df_in.experiment_id == experiment_id][df_in.table_id == table_id].variable_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d5dee47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tas', 'mrsos', 'mrro', 'tslsi', 'huss']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "available_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "173ec2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that our run has all required fields, list problem variables\n",
    "fields_of_interest = []\n",
    "missing_fields = []\n",
    "for rq in required_fields:\n",
    "    if rq not in available_fields:\n",
    "        missing_fields.append(rq)\n",
    "    else:\n",
    "        fields_of_interest.append(rq)\n",
    "\n",
    "if missing_fields != []:\n",
    "    print(f\"\"\"WARNING: data from model run:\n",
    "\n",
    "                {source_id}, \n",
    "                {table_id}, \n",
    "                {experiment_id} \n",
    "\n",
    "         missing required field(s): {missing_fields}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "916353e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_var_exact(the_dict,df_og):\n",
    "    the_keys = list(the_dict.keys())\n",
    "    #print(the_keys)\n",
    "    key0 = the_keys[0]\n",
    "    #print(key0)\n",
    "    #print(the_dict[key0])\n",
    "    hit0 = df_og[key0] == the_dict[key0]\n",
    "    if len(the_keys) > 1:\n",
    "        hitnew = hit0\n",
    "        for key in the_keys[1:]:\n",
    "            hit = df_og[key] == the_dict[key]\n",
    "            hitnew = np.logical_and(hitnew,hit)\n",
    "            #print(\"total hits: \",np.sum(hitnew))\n",
    "    else:\n",
    "        hitnew = hit0\n",
    "    df_result = df_og[hitnew]\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "782a561d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_field(variable_id, \n",
    "              df,\n",
    "              source_id=source_id,\n",
    "              experiment_id=experiment_id,\n",
    "              table_id=table_id):\n",
    "    \"\"\"\n",
    "    extracts a single variable field from the model\n",
    "    \"\"\"\n",
    "\n",
    "    var_dict = dict(source_id = source_id, variable_id = variable_id,\n",
    "                    experiment_id = experiment_id, table_id = table_id)\n",
    "    \n",
    "    local_var = fetch_var_exact(var_dict, df)\n",
    "    zstore_url = local_var['zstore'].array[0]\n",
    "    the_mapper=fsspec.get_mapper(zstore_url)\n",
    "    local_var = xr.open_zarr(the_mapper, consolidated=True)\n",
    "    return local_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85bae45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_field(df, lat, lon, years):\n",
    "    \"\"\"\n",
    "    cuts out a specified domain from an xarrray field\n",
    "    \n",
    "    lat = (minlat, maxlat)\n",
    "    lon = (minlon, maxlon)\n",
    "    \"\"\"\n",
    "    new_field = df.sel(lat=slice(lat[0],lat[1]), lon=slice(lon[0],lon[1]))\n",
    "    new_field = new_field.isel(time=(new_field.time.dt.year > years[0]))\n",
    "    new_field = new_field.isel(time=(new_field.time.dt.year < years[1]))\n",
    "    return new_field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b734326d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully acquired domain\n"
     ]
    }
   ],
   "source": [
    "# grab all fields of interest and combine\n",
    "my_fields = [get_field(field, df_in) for field in fields_of_interest]\n",
    "small_fields = [trim_field(field, lats, lons, years) for field in my_fields]\n",
    "my_ds = xr.combine_by_coords(small_fields, compat=\"broadcast_equals\", combine_attrs=\"drop_conflicts\")\n",
    "print(\"Successfully acquired domain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bde9d47d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([53085600, 53085690, 53085780, ..., 55187730, 55187820, 55187910])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cftime import date2num\n",
    "date2num(my_ds.time, \"minutes since 0000-01-01 00:00:00\", calendar=\"noleap\", has_year_zero=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "85470fe0",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a number, not 'cftime._cftime.DatetimeNoLeap'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [61]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m my_ds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m date2num(my_ds\u001b[38;5;241m.\u001b[39mtime, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminutes since 0000-01-01 00:00:00\u001b[39m\u001b[38;5;124m\"\u001b[39m, calendar\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnoleap\u001b[39m\u001b[38;5;124m\"\u001b[39m, has_year_zero\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#my_ds[\"datetimeindex\"] = my_ds.indexes['time'].to_datetimeindex()\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mmy_ds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_netcdf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./data/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43msource_id\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mexperiment_id\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/xarray/core/dataset.py:1901\u001b[0m, in \u001b[0;36mDataset.to_netcdf\u001b[0;34m(self, path, mode, format, group, engine, encoding, unlimited_dims, compute, invalid_netcdf)\u001b[0m\n\u001b[1;32m   1898\u001b[0m     encoding \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   1899\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_netcdf\n\u001b[0;32m-> 1901\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mto_netcdf\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1902\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1903\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1904\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1905\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1906\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1907\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1908\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1909\u001b[0m \u001b[43m    \u001b[49m\u001b[43munlimited_dims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munlimited_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1910\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1911\u001b[0m \u001b[43m    \u001b[49m\u001b[43minvalid_netcdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minvalid_netcdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1912\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/xarray/backends/api.py:1081\u001b[0m, in \u001b[0;36mto_netcdf\u001b[0;34m(dataset, path_or_file, mode, format, group, engine, encoding, unlimited_dims, compute, multifile, invalid_netcdf)\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m multifile:\n\u001b[1;32m   1079\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m writer, store\n\u001b[0;32m-> 1081\u001b[0m writes \u001b[38;5;241m=\u001b[39m \u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompute\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1083\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m path_or_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1084\u001b[0m     store\u001b[38;5;241m.\u001b[39msync()\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/xarray/backends/common.py:166\u001b[0m, in \u001b[0;36mArrayWriter.sync\u001b[0;34m(self, compute)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marray\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mda\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;66;03m# TODO: consider wrapping targets with dask.delayed, if this makes\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;66;03m# for any discernible difference in perforance, e.g.,\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;66;03m# targets = [dask.delayed(t) for t in self.targets]\u001b[39;00m\n\u001b[0;32m--> 166\u001b[0m delayed_store \u001b[38;5;241m=\u001b[39m \u001b[43mda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstore\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflush\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[43mregions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msources \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtargets \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/dask/array/core.py:1163\u001b[0m, in \u001b[0;36mstore\u001b[0;34m(sources, targets, lock, regions, compute, return_stored, **kwargs)\u001b[0m\n\u001b[1;32m   1161\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m compute:\n\u001b[1;32m   1162\u001b[0m     store_dsk \u001b[38;5;241m=\u001b[39m HighLevelGraph(layers, dependencies)\n\u001b[0;32m-> 1163\u001b[0m     \u001b[43mcompute_as_if_collection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mArray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore_dsk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1166\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/dask/base.py:317\u001b[0m, in \u001b[0;36mcompute_as_if_collection\u001b[0;34m(cls, dsk, keys, scheduler, get, **kwargs)\u001b[0m\n\u001b[1;32m    315\u001b[0m schedule \u001b[38;5;241m=\u001b[39m get_scheduler(scheduler\u001b[38;5;241m=\u001b[39mscheduler, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcls\u001b[39m, get\u001b[38;5;241m=\u001b[39mget)\n\u001b[1;32m    316\u001b[0m dsk2 \u001b[38;5;241m=\u001b[39m optimization_function(\u001b[38;5;28mcls\u001b[39m)(dsk, keys, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsk2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/dask/threaded.py:81\u001b[0m, in \u001b[0;36mget\u001b[0;34m(dsk, result, cache, num_workers, pool, **kwargs)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pool, multiprocessing\u001b[38;5;241m.\u001b[39mpool\u001b[38;5;241m.\u001b[39mPool):\n\u001b[1;32m     79\u001b[0m         pool \u001b[38;5;241m=\u001b[39m MultiprocessingPoolExecutor(pool)\n\u001b[0;32m---> 81\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mget_async\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_max_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m    \u001b[49m\u001b[43mget_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_thread_get_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpack_exception\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpack_exception\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;66;03m# Cleanup pools associated to dead threads\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pools_lock:\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/dask/local.py:506\u001b[0m, in \u001b[0;36mget_async\u001b[0;34m(submit, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, chunksize, **kwargs)\u001b[0m\n\u001b[1;32m    504\u001b[0m         _execute_task(task, data)  \u001b[38;5;66;03m# Re-execute locally\u001b[39;00m\n\u001b[1;32m    505\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 506\u001b[0m         \u001b[43mraise_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    507\u001b[0m res, worker_id \u001b[38;5;241m=\u001b[39m loads(res_info)\n\u001b[1;32m    508\u001b[0m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcache\u001b[39m\u001b[38;5;124m\"\u001b[39m][key] \u001b[38;5;241m=\u001b[39m res\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/dask/local.py:314\u001b[0m, in \u001b[0;36mreraise\u001b[0;34m(exc, tb)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exc\u001b[38;5;241m.\u001b[39m__traceback__ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tb:\n\u001b[1;32m    313\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[0;32m--> 314\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/dask/local.py:219\u001b[0m, in \u001b[0;36mexecute_task\u001b[0;34m(key, task_info, dumps, loads, get_id, pack_exception)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    218\u001b[0m     task, data \u001b[38;5;241m=\u001b[39m loads(task_info)\n\u001b[0;32m--> 219\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_execute_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28mid\u001b[39m \u001b[38;5;241m=\u001b[39m get_id()\n\u001b[1;32m    221\u001b[0m     result \u001b[38;5;241m=\u001b[39m dumps((result, \u001b[38;5;28mid\u001b[39m))\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/dask/core.py:119\u001b[0m, in \u001b[0;36m_execute_task\u001b[0;34m(arg, cache, dsk)\u001b[0m\n\u001b[1;32m    115\u001b[0m     func, args \u001b[38;5;241m=\u001b[39m arg[\u001b[38;5;241m0\u001b[39m], arg[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# Note: Don't assign the subtask results to a variable. numpy detects\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# temporaries by their reference count and can execute certain\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;66;03m# operations in-place.\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_execute_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ishashable(arg):\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arg\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/dask/core.py:119\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    115\u001b[0m     func, args \u001b[38;5;241m=\u001b[39m arg[\u001b[38;5;241m0\u001b[39m], arg[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# Note: Don't assign the subtask results to a variable. numpy detects\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# temporaries by their reference count and can execute certain\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;66;03m# operations in-place.\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m(\u001b[43m_execute_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m args))\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ishashable(arg):\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arg\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/dask/core.py:119\u001b[0m, in \u001b[0;36m_execute_task\u001b[0;34m(arg, cache, dsk)\u001b[0m\n\u001b[1;32m    115\u001b[0m     func, args \u001b[38;5;241m=\u001b[39m arg[\u001b[38;5;241m0\u001b[39m], arg[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# Note: Don't assign the subtask results to a variable. numpy detects\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# temporaries by their reference count and can execute certain\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;66;03m# operations in-place.\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_execute_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ishashable(arg):\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arg\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/dask/optimization.py:969\u001b[0m, in \u001b[0;36mSubgraphCallable.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    967\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minkeys):\n\u001b[1;32m    968\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m args, got \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minkeys), \u001b[38;5;28mlen\u001b[39m(args)))\n\u001b[0;32m--> 969\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/dask/core.py:149\u001b[0m, in \u001b[0;36mget\u001b[0;34m(dsk, out, cache)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m toposort(dsk):\n\u001b[1;32m    148\u001b[0m     task \u001b[38;5;241m=\u001b[39m dsk[key]\n\u001b[0;32m--> 149\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_execute_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m     cache[key] \u001b[38;5;241m=\u001b[39m result\n\u001b[1;32m    151\u001b[0m result \u001b[38;5;241m=\u001b[39m _execute_task(out, cache)\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/dask/core.py:119\u001b[0m, in \u001b[0;36m_execute_task\u001b[0;34m(arg, cache, dsk)\u001b[0m\n\u001b[1;32m    115\u001b[0m     func, args \u001b[38;5;241m=\u001b[39m arg[\u001b[38;5;241m0\u001b[39m], arg[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# Note: Don't assign the subtask results to a variable. numpy detects\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# temporaries by their reference count and can execute certain\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;66;03m# operations in-place.\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_execute_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ishashable(arg):\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arg\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/dask/utils.py:39\u001b[0m, in \u001b[0;36mapply\u001b[0;34m(func, args, kwargs)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(func, args, kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[0;32m---> 39\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     41\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/dask/array/chunk.py:276\u001b[0m, in \u001b[0;36mastype\u001b[0;34m(x, astype_dtype, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mastype\u001b[39m(x, astype_dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mastype_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'cftime._cftime.DatetimeNoLeap'"
     ]
    }
   ],
   "source": [
    "# save as netcdf as per these recommendations:\n",
    "# https://xarray.pydata.org/en/stable/user-guide/dask.html#chunking-and-performance\n",
    "# this sucks. netcdf cant handle cftime, but it is the only format xarray seems to tolerate. ugh\n",
    "my_ds[\"time\"] = date2num(my_ds.time, \"minutes since 0000-01-01 00:00:00\", calendar=\"noleap\", has_year_zero=True)\n",
    "#my_ds[\"datetimeindex\"] = my_ds.indexes['time'].to_datetimeindex()\n",
    "my_ds.to_netcdf(f\"./data/{source_id}-{experiment_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53c407d",
   "metadata": {},
   "source": [
    "## Part II: Convert to MetPy Standards and Copy Betts Fig 11\n",
    "\n",
    "moved to `make_fields.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a178b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#specific_humidity = hourly_data.huss[np.isnan(hourly_data.huss.values) == False]\n",
    "#surface_temp = hourly_data.tas[np.isnan(hourly_data.tas.values) == False]\n",
    "#td = mpcalc.dewpoint_from_specific_humidity(ps, surface_temp, specific_humidity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c874d90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plcl, tlcl = mpcalc.lcl(ps, surface_temp, td)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bec079",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8add4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add variables to generate fig 11\n",
    "#dparsed[\"td\"] = mpcalc.dewpoint_from_specific_humidity(ps, dparsed.tas.metpy.convert_units(\"kelvin\"), dparsed.huss / 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29368d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take spatial average over domain, group by hour and average each hour over time domain\n",
    "#spatial_average = dparsed.mean(dim=(\"lat\", \"lon\"))\n",
    "# need to add a step here to select only warm months with PBL development\n",
    "#hourly_data = spatial_average.groupby(dparsed.time.dt.hour).mean(dim=\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4fa46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plcl, tlcl = mpcalc.lcl(ps, spatial_average.tas * units.kelvin, spatial_average.td)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d2be2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_me = np.array(plcl)[np.isnan(np.array(plcl)) == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f54872",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(plot_me)\n",
    "#my_array = np.array([1, 2, np.nan])\n",
    "#my_array[np.isnan(my_array) == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6013a898",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, ax = plt.subplots()\n",
    "#ax.plot(hourly_data.hour[np.isnan(hourly_data.huss.values) == False], plot_this,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0f30be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#warm_months = np.array([5,6,7,8,9])\n",
    "#dparsed.isel(time=(dparsed.time.dt.month == warm_months.any()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "21d3e2f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class DatetimeNoLeap in module cftime._cftime:\n",
      "\n",
      "class DatetimeNoLeap(datetime)\n",
      " |  DatetimeNoLeap(*args, **kwargs)\n",
      " |  \n",
      " |  Phony datetime object which mimics the python datetime object,\n",
      " |  but uses the \"noleap\" (\"365_day\") calendar.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      DatetimeNoLeap\n",
      " |      datetime\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, /, *args, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  __new__(*args, **kwargs) from builtins.type\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __pyx_vtable__ = <capsule object NULL>\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from datetime:\n",
      " |  \n",
      " |  __add__(self, value, /)\n",
      " |      Return self+value.\n",
      " |  \n",
      " |  __eq__(self, value, /)\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __format__(...)\n",
      " |      datetime.__format__(self, format)\n",
      " |  \n",
      " |  __ge__(self, value, /)\n",
      " |      Return self>=value.\n",
      " |  \n",
      " |  __gt__(self, value, /)\n",
      " |      Return self>value.\n",
      " |  \n",
      " |  __hash__(self, /)\n",
      " |      Return hash(self).\n",
      " |  \n",
      " |  __le__(self, value, /)\n",
      " |      Return self<=value.\n",
      " |  \n",
      " |  __lt__(self, value, /)\n",
      " |      Return self<value.\n",
      " |  \n",
      " |  __ne__(self, value, /)\n",
      " |      Return self!=value.\n",
      " |  \n",
      " |  __radd__(self, value, /)\n",
      " |      Return value+self.\n",
      " |  \n",
      " |  __reduce__(...)\n",
      " |      datetime.__reduce__(self)\n",
      " |      special method that allows instance to be pickled\n",
      " |  \n",
      " |  __repr__(self, /)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __rsub__(self, value, /)\n",
      " |      Return value-self.\n",
      " |  \n",
      " |  __str__(self, /)\n",
      " |      Return str(self).\n",
      " |  \n",
      " |  __sub__(self, value, /)\n",
      " |      Return self-value.\n",
      " |  \n",
      " |  change_calendar(...)\n",
      " |      datetime.change_calendar(self, calendar, has_year_zero=None)\n",
      " |  \n",
      " |  isoformat(...)\n",
      " |      datetime.isoformat(self, sep=u'T', timespec=u'auto')\n",
      " |  \n",
      " |  replace(...)\n",
      " |      datetime.replace(self, **kwargs)\n",
      " |      Return datetime with new specified fields.\n",
      " |  \n",
      " |  strftime(...)\n",
      " |      datetime.strftime(self, format=None)\n",
      " |      \n",
      " |      Return a string representing the date, controlled by an explicit format\n",
      " |      string. For a complete list of formatting directives, see section\n",
      " |      'strftime() and strptime() Behavior' in the base Python documentation.\n",
      " |  \n",
      " |  timetuple(...)\n",
      " |      datetime.timetuple(self)\n",
      " |      \n",
      " |      Return a time.struct_time such as returned by time.localtime().\n",
      " |      The DST flag is -1. d.timetuple() is equivalent to\n",
      " |      time.struct_time((d.year, d.month, d.day, d.hour, d.minute,\n",
      " |      d.second, d.weekday(), yday, dst)), where yday is the\n",
      " |      day number within the current year starting with 1 for January 1st.\n",
      " |  \n",
      " |  toordinal(...)\n",
      " |      datetime.toordinal(self, fractional=False)\n",
      " |      Return (integer) julian day ordinal.\n",
      " |      \n",
      " |              Day 0 starts at noon January 1 of the year -4713 for the\n",
      " |              julian, gregorian and standard calendars (year -4712 if year\n",
      " |              zero allowed).\n",
      " |      \n",
      " |              Day 0 starts at noon on November 24 of the year -4714 for the\n",
      " |              proleptic gregorian calendar (year -4713 if year zero allowed).\n",
      " |      \n",
      " |              Day 0 starts at noon on January 1 of the year zero is for the\n",
      " |              360_day, 365_day, 366_day, all_leap and noleap calendars.\n",
      " |              \n",
      " |              If fractional=True, fractional part of day is included (default\n",
      " |              False).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from datetime:\n",
      " |  \n",
      " |  fromordinal(...)\n",
      " |      datetime.fromordinal(jday, calendar=u'standard', has_year_zero=None)\n",
      " |      Create a datetime instance from a julian day ordinal, calendar\n",
      " |              and (optionally) year zero convention (inverse of toordinal). The\n",
      " |              Julian day number is the number of days since noon UTC January 1, 4713\n",
      " |              in the proleptic julian calendar with no year zero  (November 24, 4713 \n",
      " |              in the proleptic gregorian calendar that includes the year zero). For\n",
      " |              idealized calendars, the origin is noon UTC of the year zero.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from datetime:\n",
      " |  \n",
      " |  calendar\n",
      " |  \n",
      " |  datetime_compatible\n",
      " |  \n",
      " |  day\n",
      " |  \n",
      " |  dayofwk\n",
      " |  \n",
      " |  dayofyr\n",
      " |  \n",
      " |  daysinmonth\n",
      " |  \n",
      " |  format\n",
      " |  \n",
      " |  has_year_zero\n",
      " |  \n",
      " |  hour\n",
      " |  \n",
      " |  microsecond\n",
      " |  \n",
      " |  minute\n",
      " |  \n",
      " |  month\n",
      " |  \n",
      " |  second\n",
      " |  \n",
      " |  tzinfo\n",
      " |  \n",
      " |  year\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(cftime.DatetimeNoLeap)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
