{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fcf3ec1",
   "metadata": {},
   "source": [
    "# Get Domain\n",
    "\n",
    "**Author:** Andrew Loeppky (Lots of code stolen from Jamie Byer)\n",
    "\n",
    "**Project:** Land-surface-atmosphere coupling - CMIP6 intercomparison \n",
    "\n",
    "This code grabs a climate model from the cloud, screens it for required variable fields, then selects a user specified domain and saves it to disk as a netcdf4 file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57879880",
   "metadata": {},
   "source": [
    "## Part I: Get a CMIP 6 Dataset and Select Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42eb2a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pooch\n",
    "import pandas as pd\n",
    "import fsspec\n",
    "from pathlib import Path\n",
    "import time\n",
    "import numpy as np\n",
    "import json\n",
    "import cftime\n",
    "import matplotlib.pyplot as plt\n",
    "import netCDF4 as nc\n",
    "from cftime import date2num\n",
    "\n",
    "\n",
    "# Handy metpy tutorial working with xarray:\n",
    "# https://unidata.github.io/MetPy/latest/tutorials/xarray_tutorial.html#sphx-glr-tutorials-xarray-tutorial-py\n",
    "import metpy.calc as mpcalc\n",
    "from metpy.cbook import get_test_data\n",
    "from metpy.units import units\n",
    "from metpy.plots import SkewT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58229f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attributes of the model we want to analyze (put in csv later)\n",
    "#source_id = 'CESM2-SE' \n",
    "#source_id = 'GFDL-ESM4' # working fig 11\n",
    "#source_id = \"CanESM5\" \n",
    "#source_id = 'HadGEM3-GC31-MM'\n",
    "#source_id = 'E3SM-1-0'\n",
    "#source_id = 'INM-CM5-0'\n",
    "#source_id = 'NorESM2-LM'\n",
    "#source_id = 'GFDL-ESM4'\n",
    "#source_id = 'MPI-ESM1-2-HR'\n",
    "source_id = 'CanESM5'\n",
    "\n",
    "experiment_id = 'piControl'\n",
    "table_id = '3hr'\n",
    "\n",
    "# Domain we wish to study\n",
    "\n",
    "# test domain #\n",
    "##################################################################\n",
    "#lats = (15, 20) # lat min, lat max\n",
    "#lons = (25, 29) # lon min, lon max\n",
    "#years = (100, 105) # start year, end year (note, no leap days)\n",
    "##################################################################\n",
    "\n",
    "# Thompson, MB\n",
    "lats = (54, 56) # lat min, lat max\n",
    "lons = (261, 263) # lon min, lon max\n",
    "years = (100, 300) # start year, end year (note, no leap days)\n",
    "\n",
    "save_data = False # save as netcdf for further processing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13ee3ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run CMIP6_lib.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc66ecd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "required_fields = ['tas', 'mrsos', 'huss']#, 'ps'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83efcfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get esm datastore\n",
    "odie = pooch.create(\n",
    "    path=\"./.cache\",\n",
    "    base_url=\"https://storage.googleapis.com/cmip6/\",\n",
    "    registry={\n",
    "        \"pangeo-cmip6.csv\": None\n",
    "    },\n",
    ")\n",
    "file_path = odie.fetch(\"pangeo-cmip6.csv\")\n",
    "df_in = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40779cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_in.experiment_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b69cc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_in[df_in.experiment_id == 'piControl'].table_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7cd5712",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8555/1171017956.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  available_fields = df_in[df_in.experiment_id == 'piControl'][df_in.table_id == '3hr'].variable_id.unique()\n"
     ]
    }
   ],
   "source": [
    "available_fields = df_in[df_in.experiment_id == 'piControl'][df_in.table_id == '3hr'].variable_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "173ec2c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: CanESM5\n",
      "==============================\n",
      "Contains required fields:\n",
      "    tas\n",
      "    mrsos\n",
      "    huss\n",
      "\n",
      "All required fields present\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check that our run has all required fields, list problem variables\n",
    "fields_of_interest = []\n",
    "missing_fields = []\n",
    "for rq in required_fields:\n",
    "    if rq not in available_fields:\n",
    "        missing_fields.append(rq)\n",
    "    else:\n",
    "        fields_of_interest.append(rq)\n",
    "\n",
    "\n",
    "print(f\"Model: {source_id}\\n\"+\"=\"*30)\n",
    "print(\"Contains required fields:\")\n",
    "[print(\"   \", field) for field in required_fields if field in fields_of_interest]\n",
    "\n",
    "if fields_of_interest == required_fields:\n",
    "    model_passes = True\n",
    "    print(\"\\nAll required fields present\\n\")\n",
    "else: \n",
    "    model_passes = False\n",
    "    print(\"Missing required fields:\")\n",
    "    [print(\"   \", field) for field in required_fields if field not in fields_of_interest]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71e3d4b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching domain:\n",
      "          source_id = 'CanESM5'\n",
      "          experiment_id = 'piControl'\n",
      "          table_id = '3hr'\n",
      "          lats = (54, 56)\n",
      "          lons = (261, 263)\n",
      "          years = (100, 300)\n",
      "          dataset name: my_ds (xarray Dataset)\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"Fetching domain:\n",
    "          {source_id = }\n",
    "          {experiment_id = }\n",
    "          {table_id = }\n",
    "          {lats = }\n",
    "          {lons = }\n",
    "          {years = }\n",
    "          dataset name: my_ds (xarray Dataset)\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b734326d",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# grab all fields of interest and combine\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m my_fields \u001b[38;5;241m=\u001b[39m [get_field(field, df_in) \u001b[38;5;28;01mfor\u001b[39;00m field \u001b[38;5;129;01min\u001b[39;00m fields_of_interest]\n\u001b[1;32m      3\u001b[0m small_fields \u001b[38;5;241m=\u001b[39m [trim_field(field, lats, lons, years) \u001b[38;5;28;01mfor\u001b[39;00m field \u001b[38;5;129;01min\u001b[39;00m my_fields]\n\u001b[1;32m      4\u001b[0m my_ds \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mcombine_by_coords(small_fields, compat\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbroadcast_equals\u001b[39m\u001b[38;5;124m\"\u001b[39m, combine_attrs\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrop_conflicts\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# grab all fields of interest and combine\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m my_fields \u001b[38;5;241m=\u001b[39m [\u001b[43mget_field\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfield\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_in\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m field \u001b[38;5;129;01min\u001b[39;00m fields_of_interest]\n\u001b[1;32m      3\u001b[0m small_fields \u001b[38;5;241m=\u001b[39m [trim_field(field, lats, lons, years) \u001b[38;5;28;01mfor\u001b[39;00m field \u001b[38;5;129;01min\u001b[39;00m my_fields]\n\u001b[1;32m      4\u001b[0m my_ds \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mcombine_by_coords(small_fields, compat\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbroadcast_equals\u001b[39m\u001b[38;5;124m\"\u001b[39m, combine_attrs\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrop_conflicts\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/tmp/ipykernel_8555/2593294190.py:14\u001b[0m, in \u001b[0;36mget_field\u001b[0;34m(variable_id, df, source_id, experiment_id, table_id)\u001b[0m\n\u001b[1;32m     10\u001b[0m var_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(source_id \u001b[38;5;241m=\u001b[39m source_id, variable_id \u001b[38;5;241m=\u001b[39m variable_id,\n\u001b[1;32m     11\u001b[0m                 experiment_id \u001b[38;5;241m=\u001b[39m experiment_id, table_id \u001b[38;5;241m=\u001b[39m table_id)\n\u001b[1;32m     13\u001b[0m local_var \u001b[38;5;241m=\u001b[39m fetch_var_exact(var_dict, df)\n\u001b[0;32m---> 14\u001b[0m zstore_url \u001b[38;5;241m=\u001b[39m \u001b[43mlocal_var\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mzstore\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     15\u001b[0m the_mapper\u001b[38;5;241m=\u001b[39mfsspec\u001b[38;5;241m.\u001b[39mget_mapper(zstore_url)\n\u001b[1;32m     16\u001b[0m local_var \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mopen_zarr(the_mapper, consolidated\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.9/site-packages/pandas/core/arrays/_mixins.py:272\u001b[0m, in \u001b[0;36mNDArrayBackedExtensionArray.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28mself\u001b[39m: NDArrayBackedExtensionArrayT,\n\u001b[1;32m    268\u001b[0m     key: PositionalIndexer2D,\n\u001b[1;32m    269\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NDArrayBackedExtensionArrayT \u001b[38;5;241m|\u001b[39m Any:\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mis_integer(key):\n\u001b[1;32m    271\u001b[0m         \u001b[38;5;66;03m# fast-path\u001b[39;00m\n\u001b[0;32m--> 272\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ndarray\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    273\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    274\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_box_func(result)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "# grab all fields of interest and combine\n",
    "my_fields = [get_field(field, df_in) for field in fields_of_interest]\n",
    "small_fields = [trim_field(field, lats, lons, years) for field in my_fields]\n",
    "my_ds = xr.combine_by_coords(small_fields, compat=\"broadcast_equals\", combine_attrs=\"drop_conflicts\")\n",
    "print(\"successfully acquired domain\")\n",
    "success = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85470fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as netcdf as per these recommendations:\n",
    "# https://xarray.pydata.org/en/stable/user-guide/dask.html#chunking-and-performance\n",
    "# netcdf cant handle cftime, so convert to ordinal, then back once the file is reopened\n",
    "my_ds[\"time\"] = date2num(my_ds.time, \"minutes since 0000-01-01 00:00:00\", calendar=\"noleap\", has_year_zero=True)\n",
    "\n",
    "# get rid of time bounds variable, if it exists\n",
    "try:\n",
    "    my_ds = my_ds.drop(\"time_bnds\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9080cdec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully parsed CanESM5\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if save_data:\n",
    "    print(f\"saving {source_id} to disk as netcdf\")\n",
    "    my_ds.to_netcdf(f\"./data/{source_id}-{experiment_id}.nc\", engine=\"netcdf4\")\n",
    "    print(\"success\\n\\n\")\n",
    "else:\n",
    "    print(f\"successfully parsed {source_id}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c856b51",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4003873222.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [13]\u001b[0;36m\u001b[0m\n\u001b[0;31m    need to debug get field. ugh\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "need to debug get field. ugh"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
